import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import base64
from io import StringIO
import os
from PIL import Image
import tempfile
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from latex_generator import LatexGenerator
from analysis_module import DataAnalyzer
from llm_integration import LLMProcessor
from uncertainty_calculator import UncertaintyCalculator, validate_measurement_data

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç‰©ç†å®éªŒæŠ¥å‘ŠåŠ©æ‰‹",
    page_icon="ğŸ”¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'ocr_result' not in st.session_state:
    st.session_state.ocr_result = None
if 'dataframe' not in st.session_state:
    st.session_state.dataframe = None
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None
if 'latex_output' not in st.session_state:
    st.session_state.latex_output = ""
if 'llm_response' not in st.session_state:
    st.session_state.llm_response = ""
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'context_initialized' not in st.session_state:
    st.session_state.context_initialized = False
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "qwen-flash"  # é»˜è®¤æ¨¡å‹
if 'uncertainty_conversation' not in st.session_state:
    st.session_state.uncertainty_conversation = []
if 'uncertainty_measurements' not in st.session_state:
    st.session_state.uncertainty_measurements = {}
if 'uncertainty_formula' not in st.session_state:
    st.session_state.uncertainty_formula = None
if 'uncertainty_analysis_result' not in st.session_state:
    st.session_state.uncertainty_analysis_result = None
if 'clear_uncertainty_inputs' not in st.session_state:
    st.session_state.clear_uncertainty_inputs = False
if 'show_add_success' not in st.session_state:
    st.session_state.show_add_success = False

def main():
    st.title("ğŸ”¬ ç‰©ç†å®éªŒæŠ¥å‘ŠåŠ©æ‰‹")
    st.markdown("---")
    
    # åˆ›å»ºä¾§è¾¹æ å¯¼èˆª
    st.sidebar.header("ğŸ“„ åŠŸèƒ½å¯¼èˆª")
    nav_options = ["OCRè¯†åˆ«", "æ•°æ®åˆ†æ", "è¯¯å·®åˆ†æ", "LLMåä½œ"]
    
    # é»˜è®¤æ˜¾ç¤ºç¬¬ä¸€é¡µï¼Œä¹‹åè®°ä½ç”¨æˆ·é€‰æ‹©
    current = st.session_state.get("current_page", nav_options[0])
    try:
        idx = nav_options.index(current)
    except ValueError:
        idx = 0
    
    # æ˜¾ç¤ºæ­¥éª¤æç¤º
    st.sidebar.divider()
    if current == "OCRè¯†åˆ«":
        st.sidebar.info("ğŸ“ æ­¥éª¤ 1/4\næå–å®éªŒæ•°æ®è¡¨æ ¼")
    elif current == "æ•°æ®åˆ†æ":
        st.sidebar.info("ğŸ“ æ­¥éª¤ 2/4\næ‹Ÿåˆåˆ†æä¸å¯è§†åŒ–")
    elif current == "è¯¯å·®åˆ†æ":
        st.sidebar.info("ğŸ“ æ­¥éª¤ 3/4\nä¸ç¡®å®šåº¦åˆ†æ")
    elif current == "LLMåä½œ":
        st.sidebar.info("ğŸ“ æ­¥éª¤ 4/4\næ’°å†™å®éªŒæŠ¥å‘Š")
    st.sidebar.divider()
    
    # Radio é€‰æ‹©å¯¼èˆªï¼ˆç”¨æˆ·ç‚¹å‡»æ—¶æ›´æ–° current_pageï¼‰
    page = st.sidebar.radio("é¡µé¢é€‰æ‹©", nav_options, index=idx, label_visibility="collapsed")
    st.session_state["current_page"] = page
    
    if page == "OCRè¯†åˆ«":
        ocr_page()
    elif page == "æ•°æ®åˆ†æ":
        analysis_page()
    elif page == "è¯¯å·®åˆ†æ":
        uncertainty_page()
    elif page == "LLMåä½œ":
        llm_page_new()

def ocr_page():
    st.header("ğŸ“¸ OCR è¯†åˆ«")
    st.caption("ä½¿ç”¨ AI è§†è§‰è¯†åˆ«æå–å®éªŒæ•°æ®è¡¨æ ¼")
    
    # ä¸Šä¼ å›¾åƒ
    uploaded_file = st.file_uploader("ä¸Šä¼ å®éªŒæ•°æ®å›¾åƒ", type=["jpg", "jpeg", "png", "bmp"], key="ocr_image_uploader")
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºä¸Šä¼ çš„å›¾åƒ
        image = Image.open(uploaded_file)
        st.image(image, caption="ä¸Šä¼ çš„å›¾åƒ", use_container_width=True)
        
        # ä¿å­˜ä¸Šä¼ çš„å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
            tmp_file.write(uploaded_file.getbuffer())
            image_path = tmp_file.name
        
        # ä½¿ç”¨ AI è§†è§‰è¯†åˆ«
        try:
            llm_processor = LLMProcessor(model=st.session_state.selected_model)
            
            # æå–è¡¨æ ¼
            if st.button("ğŸ“‹ æå–æ•°æ®è¡¨æ ¼"):
                with st.spinner("AI æ­£åœ¨è¯†åˆ«è¡¨æ ¼æ•°æ®..."):
                    df = llm_processor.extract_table_from_image(image_path)
                    
                    if not df.empty and "é”™è¯¯" not in df.columns:
                        # ä¿å­˜åŸå§‹è¯†åˆ«ç»“æœåˆ° session_state
                        st.session_state.ocr_dataframe = df
                        st.success("âœ… è¡¨æ ¼è¯†åˆ«å®Œæˆï¼")
                    else:
                        st.error("è¡¨æ ¼è¯†åˆ«å¤±è´¥ï¼Œè¯·å°è¯•ï¼š\n1. ç¡®ä¿å›¾åƒæ¸…æ™°\n2. è¡¨æ ¼ç»“æ„æ˜æ˜¾\n3. æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°æ®è¡¨æ ¼")
            
            # æ˜¾ç¤ºè¯†åˆ«çš„è¡¨æ ¼ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if "ocr_dataframe" in st.session_state and not st.session_state.ocr_dataframe.empty:
                df = st.session_state.ocr_dataframe
                
                st.subheader("ğŸ“Š è¯†åˆ«çš„è¡¨æ ¼")
                st.dataframe(df)
                
                # å…è®¸ç”¨æˆ·ç¼–è¾‘
                st.info("ğŸ’¡ è¯·åœ¨ä¸‹æ–¹ç¼–è¾‘è¡¨æ ¼æ•°æ®ï¼Œä¿å­˜åè¿›å…¥æ‹Ÿåˆæ­¥éª¤")
                edited_df = st.data_editor(df, num_rows="dynamic", key="table_editor")
                
                # ä¿å­˜DataFrameåˆ°ä¼šè¯çŠ¶æ€
                if st.button("âœ… ç¡®è®¤å¹¶ä¿å­˜è¡¨æ ¼", use_container_width=True):
                    st.session_state.dataframe = edited_df
                    st.session_state.ocr_dataframe = edited_df  # åŒæ—¶æ›´æ–°
                    st.success("ğŸ‰ ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼è¡¨æ ¼å·²ä¿å­˜ï¼")
                    st.info("â¬‡ï¸ **ä¸‹ä¸€æ­¥**ï¼šç‚¹å‡»å·¦ä¾§èœå• â†’ 'æ•°æ®åˆ†æ' è¿›å…¥æ‹Ÿåˆåˆ†æé˜¶æ®µ")
        
        except ValueError as e:
            st.error(f"âŒ {str(e)}")
            st.info("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® DASHSCOPE_API_KEY")
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(image_path)
        except:
            pass

def uncertainty_page():
    """
    å¯¹è¯å¼è¯¯å·®åˆ†æé¡µé¢ï¼ˆç®€æ´ç‰ˆï¼‰
    æµç¨‹ï¼šå…ˆå¡«æµ‹é‡æ•°æ®ä¸ä¸ç¡®å®šåº¦ â†’ è¾“å…¥å…¬å¼ â†’ ç³»ç»Ÿè°ƒç”¨ç¬¦å·å·¥å…·è®¡ç®— â†’ ç®€è¦å›å¤
    """
    st.header("ğŸ¯ è¯¯å·®ä¸ä¸ç¡®å®šåº¦åˆ†æ")
    st.caption("å•æ¡å½•å…¥ç‰©ç†é‡ï¼ˆç¬¦å·ã€æ•°å€¼ã€å•ä½ã€ä¸ç¡®å®šåº¦ï¼‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è§„èŒƒå…¬å¼å¹¶è°ƒç”¨ç¬¦å·å·¥å…·è®¡ç®—ã€‚")

    if "uncertainty_table" not in st.session_state:
        st.session_state.uncertainty_table = []
    if "uncertainty_summary" not in st.session_state:
        st.session_state.uncertainty_summary = None
    if "clear_uncertainty_inputs" not in st.session_state:
        st.session_state.clear_uncertainty_inputs = False
    if "show_add_success" not in st.session_state:
        st.session_state.show_add_success = False

    # è¡¨å•å¼å½•å…¥
    st.subheader("ğŸ“‹ é€é¡¹å½•å…¥æµ‹é‡é‡")
    st.caption("ä¸€æ¬¡æ·»åŠ ä¸€ä¸ªé‡:ç¬¦å·ã€æ•°å€¼ã€å•ä½ã€Aç±»Ïƒã€Bç±»Ïƒã€‚é‡å¤åŒåä¼šè¦†ç›–ã€‚")
    
    # ä½¿ç”¨è®¡æ•°å™¨å¼ºåˆ¶é‡ç½®è¡¨å•
    if "form_counter" not in st.session_state:
        st.session_state.form_counter = 0
    
    with st.form(f"uncertainty_form_{st.session_state.form_counter}"):
        c1, c2, c3, c4, c5 = st.columns([1.2, 1.2, 1, 1, 1])
        var_name = c1.text_input("ç¬¦å·", placeholder="m, v, R", key=f"var_name_{st.session_state.form_counter}")
        var_value = c2.text_input("æ•°å€¼", placeholder="0.0", key=f"var_value_{st.session_state.form_counter}")
        var_unit = c3.text_input("å•ä½", placeholder="kg, m/s", key=f"var_unit_{st.session_state.form_counter}")
        var_a = c4.text_input("Aç±»(Ïƒ)", placeholder="0.0", key=f"var_a_{st.session_state.form_counter}")
        var_b = c5.text_input("Bç±»(Ïƒ)", placeholder="0.0", key=f"var_b_{st.session_state.form_counter}")
        submitted = st.form_submit_button("ä¿å­˜/æ›´æ–°è¯¥å˜é‡", type="primary", use_container_width=True)
    
    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if st.session_state.show_add_success:
        st.success("âœ… å·²æˆåŠŸæ·»åŠ /æ›´æ–°å˜é‡ï¼")
        st.session_state.show_add_success = False

    if submitted:
        name = var_name.strip()
        if not name:
            st.warning("è¯·å…ˆå¡«å†™å˜é‡ç¬¦å·")
        else:
            try:
                val = float(var_value.strip()) if var_value.strip() else 0.0
                a_val = float(var_a.strip()) if var_a.strip() else 0.0
                b_val = float(var_b.strip()) if var_b.strip() else 0.0
                
                entry = {
                    "å˜é‡": name,
                    "æ•°å€¼": val,
                    "å•ä½": var_unit.strip(),
                    "Aç±»(Ïƒ)": a_val,
                    "Bç±»(Ïƒ)": b_val
                }
                # è¦†ç›–åŒåå˜é‡
                replaced = False
                for idx, row in enumerate(st.session_state.uncertainty_table):
                    if row.get("å˜é‡", "").strip() == name:
                        st.session_state.uncertainty_table[idx] = entry
                        replaced = True
                        break
                if not replaced:
                    st.session_state.uncertainty_table.append(entry)
                st.session_state.uncertainty_analysis_result = None
                st.session_state.uncertainty_summary = None
                # å¢åŠ è®¡æ•°å™¨ä»¥é‡ç½®è¡¨å•
                st.session_state.form_counter += 1
                st.session_state.show_add_success = True
                st.rerun()
            except ValueError:
                st.error("æ•°å€¼æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")

    # å·²æ·»åŠ çš„æµ‹é‡é‡é¢„è§ˆ
    st.markdown("**å½“å‰æµ‹é‡é‡**")
    if st.session_state.uncertainty_table:
        preview_df = pd.DataFrame(st.session_state.uncertainty_table)
        st.dataframe(preview_df, use_container_width=True, height=240)

        col_del = st.columns([2, 1, 1])
        with col_del[0]:
            st.caption("Aç±»=ç»Ÿè®¡è¯¯å·®ï¼ŒBç±»=ç³»ç»Ÿè¯¯å·®ï¼›å•ä½éœ€ä¸€è‡´ã€‚")
        with col_del[1]:
            remove_opt = st.selectbox("åˆ é™¤å˜é‡", options=["æ— "] + [row["å˜é‡"] for row in st.session_state.uncertainty_table], key="uncertainty_remove_opt")
        with col_del[2]:
            if st.button("ğŸ—‘ï¸ åˆ é™¤æ‰€é€‰") and remove_opt != "æ— ":
                st.session_state.uncertainty_table = [row for row in st.session_state.uncertainty_table if row.get("å˜é‡") != remove_opt]
                st.session_state.uncertainty_analysis_result = None
                st.session_state.uncertainty_summary = None
                st.rerun()

        if st.button("â™»ï¸ æ¸…ç©ºå…¨éƒ¨æ•°æ®", type="secondary"):
            st.session_state.uncertainty_table = []
            st.session_state.uncertainty_measurements = {}
            st.session_state.uncertainty_analysis_result = None
            st.session_state.uncertainty_summary = None
            st.rerun()
    else:
        st.info("æš‚æ— æµ‹é‡é‡ï¼Œè¯·ç”¨ä¸Šæ–¹è¡¨å•æ·»åŠ ã€‚")

    # æ•´ç†è¡¨æ ¼ä¸ºè®¡ç®—æ‰€éœ€ç»“æ„ï¼ˆä¾›å¯¹è¯ä½¿ç”¨ï¼‰
    measurements = {}
    for row in st.session_state.uncertainty_table:
        name = str(row.get("å˜é‡", "")).strip()
        if not name:
            continue
        measurements[name] = {
            "value": float(row.get("æ•°å€¼", 0) or 0),
            "unit": row.get("å•ä½", ""),
            "a_uncertainty": float(row.get("Aç±»(Ïƒ)", 0) or 0),
            "b_uncertainty": float(row.get("Bç±»(Ïƒ)", 0) or 0),
        }
    st.session_state.uncertainty_measurements = measurements

    # èŠå¤©åŒºï¼ˆè¾“å…¥æ¡†åœ¨ä¸‹ï¼‰
    st.divider()
    st.subheader("ğŸ’¬ ä¸ç¡®å®šåº¦å¯¹è¯")
    st.caption("åœ¨ä¸‹æ–¹å¯¹è¯ä¸­æè¿°å®éªŒå…¬å¼å’Œæµ‹é‡æƒ…å†µï¼ŒAIä¼šå¼•å¯¼ä½ å®Œæˆä¸ç¡®å®šåº¦è®¡ç®—ã€‚")
    chat_container = st.container()
    if not st.session_state.uncertainty_conversation:
        st.session_state.uncertainty_conversation = [
            {
                "role": "assistant",
                "content": "ä½ å¥½ï¼æˆ‘ä¼šå¸®ä½ å®Œæˆä¸ç¡®å®šåº¦åˆ†æã€‚\n\nè¯·å‘Šè¯‰æˆ‘ï¼š\n1. å®éªŒçš„è®¡ç®—å…¬å¼ï¼ˆå¯ä»¥ç”¨è‡ªç„¶è¯­è¨€æè¿°ï¼Œå¦‚'åŠ¨èƒ½ç­‰äºäºŒåˆ†ä¹‹ä¸€ä¹˜ä»¥è´¨é‡ä¹˜ä»¥é€Ÿåº¦å¹³æ–¹'ï¼‰\n2. å„å˜é‡çš„æµ‹é‡å€¼ã€å•ä½å’Œä¸ç¡®å®šåº¦ï¼ˆAç±»å’ŒBç±»ï¼‰\n\næˆ‘ä¼šå¸®ä½ è§„èŒƒå…¬å¼å¹¶è°ƒç”¨ç¬¦å·å·¥å…·è®¡ç®—ã€‚"
            }
        ]

    with chat_container:
        for msg in st.session_state.uncertainty_conversation:
            with st.chat_message(msg["role"], avatar="ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"):
                st.markdown(msg["content"])

    user_msg = st.chat_input("æè¿°å…¬å¼æˆ–æé—®ï¼ˆä¾‹å¦‚ï¼šè®¡ç®—åŠ¨èƒ½ï¼Œå·²çŸ¥è´¨é‡å’Œé€Ÿåº¦ï¼‰")
    if user_msg:
        st.session_state.uncertainty_conversation.append({"role": "user", "content": user_msg})
        try:
            llm = LLMProcessor(model=st.session_state.selected_model)
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                ph = st.empty()
                resp = ""
                thinking_text = ""
                tool_calls_text = ""
                
                # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨plusæ¨¡å‹å¹¶å¯ç”¨æ·±åº¦æ€è€ƒ
                enable_thinking = "plus" in st.session_state.selected_model
                
                # è°ƒç”¨æ™ºèƒ½ä¸ç¡®å®šåº¦å¯¹è¯ï¼ˆå¯èƒ½è§¦å‘è®¡ç®—ï¼‰
                for chunk in llm.smart_uncertainty_conversation(
                    user_msg,
                    st.session_state.uncertainty_conversation[:-1],
                    measurements,
                    enable_thinking=enable_thinking
                ):
                    if isinstance(chunk, dict):
                        chunk_type = chunk.get("type", "")
                        chunk_text = chunk.get("text", "")
                        
                        if chunk_type == "thinking":
                            thinking_text += chunk_text
                        elif chunk_type == "content":
                            resp += chunk_text
                        elif chunk_type == "tool_call":
                            # æ˜¾ç¤ºMCPå·¥å…·è°ƒç”¨
                            tool_calls_text += f"\n\nğŸ”§ **è°ƒç”¨å·¥å…·**: {chunk.get('tool_name', 'unknown')}\n"
                        elif chunk_type == "calculation_result":
                            # ä¿å­˜è®¡ç®—ç»“æœ
                            calc_result = chunk.get("result")
                            if calc_result and calc_result.get("success"):
                                st.session_state.uncertainty_analysis_result = calc_result
                                st.session_state.uncertainty_summary = calc_result.get("summary", "")
                                
                                # æ˜¾ç¤ºè¯¦ç»†è®¡ç®—ç»“æœ
                                result_display = f"\n\n---\n\nğŸ¯ **è®¡ç®—ç»“æœ**\n\n"
                                result_display += f"**åŸå§‹å…¬å¼**: {calc_result.get('raw_formula', 'N/A')}\n\n"
                                result_display += f"**è§„èŒƒåŒ–å…¬å¼**: `{calc_result.get('normalized_formula', 'N/A')}`\n\n"
                                
                                # æ˜¾ç¤ºLaTeXå…¬å¼
                                if calc_result.get('partial_derivatives'):
                                    result_display += "**åå¯¼æ•°**:\n\n"
                                    for var, deriv_info in calc_result['partial_derivatives'].items():
                                        latex_expr = deriv_info.get('latex', '')
                                        value = deriv_info.get('value', 0)
                                        result_display += f"- $\\frac{{\\partial f}}{{\\partial {var}}} = {latex_expr}$ â‰ˆ {value:.4g}\n"
                                    result_display += "\n"
                                
                                # ç»“æœä¸ä¸ç¡®å®šåº¦
                                result_display += f"**æœ€ç»ˆç»“æœ**: {calc_result.get('result', 0):.6g} Â± {calc_result.get('uncertainty_total', 0):.4g}\n\n"
                                result_display += f"- Aç±»ä¸ç¡®å®šåº¦: {calc_result.get('uncertainty_a', 0):.4g}\n"
                                result_display += f"- Bç±»ä¸ç¡®å®šåº¦: {calc_result.get('uncertainty_b', 0):.4g}\n"
                                result_display += f"- ç›¸å¯¹ä¸ç¡®å®šåº¦: {calc_result.get('relative_uncertainty', 0):.2%}\n\n"
                                
                                # å„å˜é‡è´¡çŒ®
                                if calc_result.get('contributions'):
                                    result_display += "**å„å˜é‡è´¡çŒ®å æ¯”**:\n\n"
                                    sorted_contrib = sorted(calc_result['contributions'].items(), key=lambda x: x[1], reverse=True)
                                    for var, contrib in sorted_contrib:
                                        bar_length = int(contrib / 5)  # æ¯5%ä¸€ä¸ªæ–¹å—
                                        bar = "â–ˆ" * bar_length
                                        result_display += f"- **{var}**: {contrib:.1f}% {bar}\n"
                                
                                resp += result_display
                    else:
                        resp += str(chunk)
                    
                    # å®æ—¶æ˜¾ç¤º
                    display_parts = []
                    if thinking_text:
                        display_parts.append(f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```")
                    if tool_calls_text:
                        display_parts.append(tool_calls_text)
                    if resp:
                        display_parts.append(resp)
                    
                    display_text = "\n\n---\n\n".join(display_parts) + "â–Œ"
                    ph.markdown(display_text, unsafe_allow_html=True)
                
                # æœ€ç»ˆæ˜¾ç¤º
                display_parts = []
                if thinking_text:
                    display_parts.append(f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```")
                if tool_calls_text:
                    display_parts.append(tool_calls_text)
                if resp:
                    display_parts.append(resp)
                
                display_text = "\n\n---\n\n".join(display_parts)
                ph.markdown(display_text, unsafe_allow_html=True)
                
                st.session_state.uncertainty_conversation.append({"role": "assistant", "content": resp})
            st.rerun()
        except Exception as e:
            st.error(f"LLM äº¤äº’å¤±è´¥: {str(e)}")

    # ä¼ é€’ç»“æœåˆ°å†™ä½œé¡µï¼ˆç§»åˆ°å¯¹è¯ä¸‹æ–¹ï¼‰
    st.divider()
    if st.button("ğŸ“ ä¼ ç»™å†™ä½œAI", disabled=st.session_state.uncertainty_analysis_result is None, use_container_width=True, type="primary"):
        if st.session_state.uncertainty_analysis_result:
            # åŒæ—¶ä¼ é€’è®¡ç®—ç»“æœå’Œå¯¹è¯å†å²
            st.session_state.passed_uncertainty_result = st.session_state.uncertainty_analysis_result
            st.session_state.passed_uncertainty_conversation = st.session_state.uncertainty_conversation
            st.success("âœ… å·²å°†è¯¯å·®åˆ†æç»“æœå’Œå¯¹è¯å†å²ä¼ é€’åˆ°å†™ä½œé¡µé¢ï¼")
            # è‡ªåŠ¨åˆ‡æ¢åˆ°LLMåä½œé¡µ
            st.session_state["current_page"] = "LLMåä½œ"
            st.rerun()
        else:
            st.warning("è¯·å…ˆå®Œæˆä¸ç¡®å®šåº¦è®¡ç®—åå†ä¼ é€’ç»“æœ")

def analysis_page():
    st.header("ğŸ“ˆ æ•°æ®åˆ†æä¸æ‹Ÿåˆ")
    
    # æ•°æ®æ¥æºé€‰æ‹©
    st.subheader("ğŸ“Š æ•°æ®æ¥æº")
    
    # è·å–å¯ç”¨çš„æ•°æ®æº
    has_ocr_data = st.session_state.dataframe is not None and not st.session_state.dataframe.empty
    
    # æ•°æ®æºé€‰é¡¹å¡
    if has_ocr_data:
        st.info("âœ… å·²ä» OCR è¯†åˆ«è·å¾—æ•°æ®è¡¨")
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æ¥æº",
            ["ä½¿ç”¨ OCR è¯†åˆ«çš„è¡¨æ ¼", "ä¸Šä¼  CSV æ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥æ•°æ®"],
            help="ä¼˜å…ˆæ¨èä½¿ç”¨ OCR è¯†åˆ«çš„è¡¨æ ¼"
        )
    else:
        st.warning("âš ï¸ æœªæ£€æµ‹åˆ° OCR è¯†åˆ«çš„è¡¨æ ¼")
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æ¥æº",
            ["ä¸Šä¼  CSV æ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥æ•°æ®"],
            help="è¯·é€‰æ‹©ä¸€ç§æ–¹å¼æä¾›æ•°æ®"
        )
    
    df = None
    
    # æ•°æ®æ¥æº 1: OCR è¯†åˆ«çš„è¡¨æ ¼
    if data_source == "ä½¿ç”¨ OCR è¯†åˆ«çš„è¡¨æ ¼" and has_ocr_data:
        df = st.session_state.dataframe
        st.subheader("ğŸ“‹ OCR è¯†åˆ«çš„è¡¨æ ¼")
        col1, col2 = st.columns([4, 1])
        with col1:
            st.dataframe(df, use_container_width=True)
        with col2:
            csv_data = df.to_csv(index=False)
            st.download_button(
                "ğŸ“‹ å¤åˆ¶è¡¨æ ¼\n(CSVæ ¼å¼)",
                data=csv_data,
                file_name="data_table.csv",
                mime="text/csv",
                use_container_width=True
            )
        st.caption("ğŸ’¡ æç¤ºï¼šå¯åœ¨ä¸‹æ–¹ç¼–è¾‘æ•°æ®æˆ–é€‰æ‹©å…¶ä»–æ•°æ®æº")
    
    # æ•°æ®æ¥æº 2: CSV ä¸Šä¼ 
    elif data_source == "ä¸Šä¼  CSV æ–‡ä»¶":
        st.subheader("ğŸ“¥ ä¸Šä¼  CSV æ–‡ä»¶")
        uploaded_csv = st.file_uploader("é€‰æ‹© CSV æ–‡ä»¶", type="csv", key="analysis_csv_upload")
        
        if uploaded_csv is not None:
            try:
                df = pd.read_csv(uploaded_csv)
                st.success("âœ… CSV æ–‡ä»¶åŠ è½½æˆåŠŸ")
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.dataframe(df, use_container_width=True)
                with col2:
                    csv_data = df.to_csv(index=False)
                    st.download_button(
                        "ğŸ“‹ å¤åˆ¶è¡¨æ ¼\n(CSVæ ¼å¼)",
                        data=csv_data,
                        file_name="data_table_export.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                
                st.info("ğŸ’¡ æ•°æ®å·²åŠ è½½ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç¡®è®¤ä½¿ç”¨")
                if st.button("âœ… ç¡®è®¤å¹¶ä½¿ç”¨æ­¤æ•°æ®", use_container_width=True):
                    st.session_state.dataframe = df
                    st.success("âœ… æ•°æ®å·²ä¿å­˜ï¼")
                    st.rerun()
            except Exception as e:
                st.error(f"âŒ CSV è¯»å–å¤±è´¥: {e}")
                df = None
        else:
            st.info("ğŸ“‚ è¯·ä¸Šä¼ ä¸€ä¸ª CSV æ–‡ä»¶ï¼ˆåŒ…å«è¡¨å¤´å’Œæ•°å€¼æ•°æ®ï¼‰")
    
    # æ•°æ®æ¥æº 3: æ‰‹åŠ¨è¾“å…¥
    elif data_source == "æ‰‹åŠ¨è¾“å…¥æ•°æ®":
        st.subheader("âœï¸ æ‰‹åŠ¨è¾“å…¥æ•°æ®")
        
        # ä¸¤ç§æ‰‹åŠ¨è¾“å…¥æ–¹å¼
        input_method = st.radio("è¾“å…¥æ–¹å¼", ["è¡¨æ ¼ç¼–è¾‘å™¨", "ç²˜è´´ CSV æ ¼å¼æ–‡æœ¬"], horizontal=True)
        
        if input_method == "è¡¨æ ¼ç¼–è¾‘å™¨":
            st.caption("ä½¿ç”¨ä¸‹æ–¹ç¼–è¾‘å™¨è¾“å…¥æ•°æ®ï¼ˆå¯æ·»åŠ /åˆ é™¤è¡Œï¼‰")
            
            # åˆå§‹åŒ–ç¤ºä¾‹æ•°æ®
            if "manual_data_df" not in st.session_state:
                st.session_state.manual_data_df = pd.DataFrame({
                    "åˆ—å1": [1.0, 2.0, 3.0],
                    "åˆ—å2": [2.0, 4.0, 6.0]
                })
            
            edited_df = st.data_editor(
                st.session_state.manual_data_df,
                num_rows="dynamic",
                key="manual_data_editor",
                use_container_width=True
            )
            
            st.info("ğŸ’¡ ç¼–è¾‘å®Œæˆåï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç¡®è®¤ä½¿ç”¨")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("âœ… ç¡®è®¤æ‰‹åŠ¨è¾“å…¥çš„æ•°æ®", use_container_width=True):
                    st.session_state.dataframe = edited_df
                    st.session_state.manual_data_df = edited_df
                    st.success("ğŸ‰ æ•°æ®å·²ä¿å­˜ï¼")
                    st.info("â¬‡ï¸ **ä¸‹ä¸€æ­¥**ï¼šç‚¹å‡»å·¦ä¾§èœå• â†’ 'æ•°æ®åˆ†æ' è¿›å…¥æ‹Ÿåˆåˆ†æé˜¶æ®µ")
                    st.rerun()
            with col2:
                csv_export = edited_df.to_csv(index=False)
                st.download_button(
                    "ğŸ“‹ å¯¼å‡ºä¸º CSV",
                    data=csv_export,
                    file_name="manual_data.csv",
                    mime="text/csv"
                )
            
            df = edited_df
        
        else:  # ç²˜è´´ CSV æ–‡æœ¬
            st.caption("ç²˜è´´ CSV æ ¼å¼çš„æ–‡æœ¬ï¼ˆä»¥é€—å·åˆ†éš”ï¼Œç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼‰")
            csv_text = st.text_area(
                "CSV æ ¼å¼æ–‡æœ¬",
                value="åˆ—å1,åˆ—å2\n1.0,2.0\n2.0,4.0\n3.0,6.0",
                height=150,
                key="manual_csv_text"
            )
            
            if st.button("ğŸ”„ è§£æ CSV æ–‡æœ¬"):
                try:
                    from io import StringIO
                    df = pd.read_csv(StringIO(csv_text))
                    st.success("âœ… è§£ææˆåŠŸ")
                    st.dataframe(df, use_container_width=True)
                    
                    st.info("ğŸ’¡ è§£æå®Œæˆï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç¡®è®¤ä½¿ç”¨")
                    if st.button("âœ… ç¡®è®¤ä½¿ç”¨æ­¤æ•°æ®", use_container_width=True):
                        st.session_state.dataframe = df
                        st.success("ğŸ‰ æ•°æ®å·²ä¿å­˜ï¼")
                        st.info("â¬‡ï¸ **ä¸‹ä¸€æ­¥**ï¼šç‚¹å‡»å·¦ä¾§èœå• â†’ 'æ•°æ®åˆ†æ' è¿›å…¥æ‹Ÿåˆåˆ†æé˜¶æ®µ")
                        st.rerun()
                except Exception as e:
                    st.error(f"âŒ è§£æå¤±è´¥: {e}")
                    st.info("ğŸ“Œ ç¡®ä¿ CSV æ ¼å¼æ­£ç¡®ï¼šç¬¬ä¸€è¡Œä¸ºåˆ—åï¼Œæ•°æ®ç”¨é€—å·åˆ†éš”")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•°æ®
    if df is None or df.empty:
        st.warning("âš ï¸ æš‚æ— å¯ç”¨æ•°æ®ï¼Œè¯·å®Œæˆä¸Šè¿°æ­¥éª¤")
        return
    
    # ===== æ•°æ®é¢„å¤„ç†å’Œåˆ†æ =====
    st.divider()
    st.subheader("âš™ï¸ åˆ†æå‚æ•°è®¾ç½®")
    
    # é€‰æ‹©åˆ—è¿›è¡Œåˆ†æ
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) < 2:
        st.error("âŒ æ•°æ®ä¸åŒ…å«è¶³å¤Ÿçš„æ•°å€¼åˆ—ï¼ˆè‡³å°‘éœ€è¦ 2 åˆ—ï¼‰")
        st.info("è¯·ä¸Šä¼ åŒ…å«è‡³å°‘ 2 åˆ—æ•°å€¼æ•°æ®çš„æ–‡ä»¶")
        return
    
    # é€‰æ‹© Xã€Y åˆ—
    col1, col2 = st.columns(2)
    x_col = col1.selectbox("é€‰æ‹©Xè½´åˆ—", numeric_cols, key="x_col")
    y_col = col2.selectbox("é€‰æ‹©Yè½´åˆ—", numeric_cols, key="y_col")

    # é«˜çº§é€‰é¡¹å¼€å…³
    advanced = st.checkbox("é«˜çº§é€‰é¡¹", value=False, help="å¼€å¯åå¯é€‰æ‹©å¯¹æ•°æ‹Ÿåˆã€è¯¯å·®æ£’ã€é‡‡æ ·ç‡ç­‰")

    # æ‹Ÿåˆç±»å‹
    analysis_options = ["çº¿æ€§æ‹Ÿåˆ", "å‚…é‡Œå¶å˜æ¢"]
    if advanced:
        analysis_options.insert(1, "å¯¹æ•°æ‹Ÿåˆ (x>0)")
        analysis_options.insert(2, "åŒå¯¹æ•°æ‹Ÿåˆ (x>0, y>0)")
    analysis_type = st.selectbox("é€‰æ‹©åˆ†æç±»å‹", analysis_options)

    # è¯¯å·®åˆ—ï¼ˆä»…æ‹Ÿåˆç±»ä½¿ç”¨ï¼‰
    x_err = y_err = None
    if advanced and (analysis_type == "çº¿æ€§æ‹Ÿåˆ" or analysis_type.startswith("å¯¹æ•°æ‹Ÿåˆ") or analysis_type.startswith("åŒå¯¹æ•°æ‹Ÿåˆ")):
        err_cols = ["æ— "] + numeric_cols
        err_c1, err_c2 = st.columns(2)
        x_err_col = err_c1.selectbox("X è¯¯å·®åˆ—", err_cols, key="x_err_col")
        y_err_col = err_c2.selectbox("Y è¯¯å·®åˆ—", err_cols, key="y_err_col")
        if x_err_col != "æ— ":
            x_err = df[x_err_col].tolist()
        if y_err_col != "æ— ":
            y_err = df[y_err_col].tolist()

    # é‡‡æ ·ç‡ï¼ˆFFT é«˜çº§ï¼‰
    sampling_rate = 1.0
    if analysis_type == "å‚…é‡Œå¶å˜æ¢" and advanced:
        sampling_rate = st.number_input("é‡‡æ ·ç‡ (Hz)", min_value=0.0001, value=1.0, step=0.1)

    # åæ ‡è½´æ ‡ç­¾ï¼ˆå…è®¸è‡ªå®šä¹‰ç‰©ç†é‡åç§°ï¼‰
    axis_c1, axis_c2 = st.columns(2)
    xlabel_in = axis_c1.text_input("X è½´æ ‡ç­¾", value=str(x_col) if x_col else "X")
    ylabel_in = axis_c2.text_input("Y è½´æ ‡ç­¾", value=str(y_col) if y_col else "Y")

    if x_col and y_col:
        x_data = df[x_col].tolist()
        y_data = df[y_col].tolist()

        if st.button("ğŸ” æ‰§è¡Œåˆ†æ"):
            analyzer = DataAnalyzer()

            if analysis_type == "çº¿æ€§æ‹Ÿåˆ":
                with st.spinner("æ­£åœ¨æ‰§è¡Œçº¿æ€§æ‹Ÿåˆ..."):
                    slope, intercept, r_squared, slope_err, intercept_err, chi2r = analyzer.linear_fit(
                        x_data, y_data, y_err=y_err, x_err=x_err
                    )

                    st.subheader("ğŸ“ˆ çº¿æ€§æ‹Ÿåˆç»“æœ")
                    c1, c2, c3 = st.columns(3)
                    slope_str, slope_unc = analyzer.format_with_uncertainty(slope, slope_err)
                    intercept_str, intercept_unc = analyzer.format_with_uncertainty(intercept, intercept_err)
                    c1.metric("æ–œç‡", f"{slope_str} Â± {slope_unc}")
                    c2.metric("æˆªè·", f"{intercept_str} Â± {intercept_unc}")
                    c3.metric("åŠ æƒ RÂ²", f"{r_squared:.4f}")
                    st.caption(f"Reduced $\\chi^2$ = {chi2r:.3f}")

                    # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°ï¼Œå‘½åï¼šçº¿æ€§æ‹Ÿåˆ+æ—¶é—´æˆ³
                    plots_dir = os.path.join(os.getcwd(), "plots")
                    os.makedirs(plots_dir, exist_ok=True)
                    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
                    fname = f"çº¿æ€§æ‹Ÿåˆ_{ts}.png"
                    full_path = os.path.join(plots_dir, fname)

                    plot_data = analyzer.plot_linear_fit(
                        x_data, y_data,
                        title=f"{x_col} vs {y_col} Linear Fit",
                        xlabel=xlabel_in,
                        ylabel=ylabel_in,
                        x_err=x_err,
                        y_err=y_err,
                        slope=slope,
                        intercept=intercept,
                        r_squared=r_squared,
                        slope_err=slope_err,
                        intercept_err=intercept_err,
                        save_path=full_path
                    )

                    st.image(f"data:image/png;base64,{plot_data}", caption="çº¿æ€§æ‹Ÿåˆå›¾")

                    st.session_state.analysis_result = {
                        "type": "linear_fit",
                        "slope": slope,
                        "intercept": intercept,
                        "r_squared": r_squared,
                        "slope_err": slope_err,
                        "intercept_err": intercept_err,
                        "plot_data": plot_data
                    }
                    st.success("âœ… åˆ†æå®Œæˆï¼")
                    # ä¿å­˜ç»Ÿä¸€çš„åˆ†æä¸Šä¸‹æ–‡ï¼Œä¾› LLM åä½œé¡µä½¿ç”¨
                    st.session_state["analysis_payload"] = {
                        "type": "linear",
                        "x_col": x_col,
                        "y_col": y_col,
                        "slope": slope,
                        "intercept": intercept,
                        "slope_err": slope_err,
                        "intercept_err": intercept_err,
                        "r_squared": r_squared,
                        "reduced_chi2": chi2r,
                        "figure_hint": "çº¿æ€§æ‹Ÿåˆå›¾"
                    }
                    # ä¿å­˜å›¾åƒæ–‡ä»¶ä¿¡æ¯ä¾› LLM åä½œé¡µä½¿ç”¨
                    st.session_state["plot_file_path"] = full_path
                    st.session_state["plot_file_name"] = fname
                    
                    # ç¬¬ä¸€æ­¥ï¼šçªå‡ºæ˜¾ç¤ºä¸‹ä¸€æ­¥æç¤º
                    st.divider()
                    st.success("ğŸ‰ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼çº¿æ€§æ‹Ÿåˆå·²ç”Ÿæˆï¼")
                    with st.container(border=True):
                        st.markdown("### ğŸ’¡ ä¸‹ä¸€æ­¥")
                        st.markdown("""
                        åœ¨å·¦ä¾§èœå•é€‰æ‹© **'LLMåä½œ'** ä¸å¤§è¯­è¨€æ¨¡å‹å…±åŒæ’°å†™å®éªŒæ€»ç»“
                        
                        - ğŸ“ Plané˜¶æ®µï¼šæ¾„æ¸…å®éªŒèƒŒæ™¯å’Œæ–¹æ³•
                        - âœï¸ Acté˜¶æ®µï¼šç”Ÿæˆç»“æœåˆ†æå’Œè®¨è®º
                        """)
                    
                    # ç¬¬äºŒæ­¥ï¼šè‡ªå®šä¹‰é€‰é¡¹ï¼ˆå¯é€‰ï¼‰
                    st.divider()
                    st.subheader("ğŸ”§ è‡ªå®šä¹‰æ‹Ÿåˆç»“æœï¼ˆå¯é€‰ï¼‰")
                    
                    custom_tab1, custom_tab2 = st.tabs(["ğŸ“ è¾“å…¥LaTeX", "ğŸ“¥ å¯¼å…¥CSV"])
                    
                    with custom_tab1:
                        st.caption("æ‰‹åŠ¨è¾“å…¥è‡ªå®šä¹‰ LaTeX å†…å®¹ï¼ˆå¯è¦†ç›–è‡ªåŠ¨ç”Ÿæˆçš„ç»“æœï¼‰")
                        custom_latex = st.text_area("LaTeXä»£ç ", height=150, key="linear_latex")
                        if custom_latex:
                            st.session_state["custom_latex"] = custom_latex
                            st.info("âœ… è‡ªå®šä¹‰ LaTeX å·²ä¿å­˜ï¼Œå°†åœ¨ä¸‹è½½æ—¶åŒ…å«")
                    
                    with custom_tab2:
                        st.caption("å¯¼å…¥ CSV æ–‡ä»¶ä»¥æ›´æ–°æˆ–æ‰©å±•æ•°æ®")
                        csv_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type="csv", key="linear_csv_upload")
                        if csv_file:
                            try:
                                new_df = pd.read_csv(csv_file)
                                st.dataframe(new_df)
                                if st.button("âœ… ç¡®è®¤å¯¼å…¥", key="linear_csv_confirm"):
                                    st.session_state.dataframe = new_df
                                    st.success("âœ… æ•°æ®å·²æ›´æ–°ï¼Œè¯·é‡æ–°æ‰§è¡Œåˆ†æ")
                            except Exception as e:
                                st.error(f"âŒ CSV å¯¼å…¥å¤±è´¥: {e}")
                    
                    # ç¬¬ä¸‰æ­¥ï¼šå¤åˆ¶æŒ‰é’®ï¼ˆä½œä¸ºè¾…åŠ©åŠŸèƒ½ï¼‰
                    st.divider()
                    st.subheader("ğŸ“‹ å¤åˆ¶æ‹Ÿåˆç»“æœï¼ˆå¯é€‰ï¼‰")
                    col1, col2 = st.columns(2)
                    with col1:
                        result_txt = f"""çº¿æ€§æ‹Ÿåˆç»“æœï¼š
æ–œç‡: {slope_str} Â± {slope_unc}
æˆªè·: {intercept_str} Â± {intercept_unc}
åŠ æƒRÂ²: {r_squared:.4f}
Reduced Ï‡Â²: {chi2r:.3f}
å›¾æ–‡ä»¶: {fname}"""
                        st.download_button(
                            "ğŸ“‹ å¤åˆ¶æ‹Ÿåˆç»“æœ",
                            data=result_txt,
                            file_name="linear_fit_result.txt",
                            mime="text/plain",
                            use_container_width=True
                        )
                    with col2:
                        st.caption("ğŸ’¡ ç‚¹å‡»ä¸‹è½½æ‹Ÿåˆç»“æœ\nï¼ˆå¯åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ï¼‰")

            elif analysis_type.startswith("å¯¹æ•°æ‹Ÿåˆ"):
                try:
                    with st.spinner("æ­£åœ¨æ‰§è¡Œå¯¹æ•°æ‹Ÿåˆ..."):
                        slope, intercept, r_squared, slope_err, intercept_err, chi2r = analyzer.log_fit(
                            x_data, y_data, y_err=y_err
                        )

                        st.subheader("ğŸ“ˆ å¯¹æ•°æ‹Ÿåˆç»“æœ")
                        c1, c2, c3 = st.columns(3)
                        slope_str, slope_unc = analyzer.format_with_uncertainty(slope, slope_err)
                        intercept_str, intercept_unc = analyzer.format_with_uncertainty(intercept, intercept_err)
                        c1.metric("ç³»æ•° a", f"{slope_str} Â± {slope_unc}")
                        c2.metric("æˆªè· b", f"{intercept_str} Â± {intercept_unc}")
                        c3.metric("åŠ æƒ RÂ²", f"{r_squared:.4f}")
                        st.caption(f"Reduced $\\chi^2$ = {chi2r:.3f}")

                        # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°ï¼Œå‘½åï¼šå¯¹æ•°æ‹Ÿåˆ+æ—¶é—´æˆ³
                        plots_dir = os.path.join(os.getcwd(), "plots")
                        os.makedirs(plots_dir, exist_ok=True)
                        ts = datetime.now().strftime("%Y%m%d-%H%M%S")
                        fname = f"å¯¹æ•°æ‹Ÿåˆ_{ts}.png"
                        full_path = os.path.join(plots_dir, fname)

                        plot_data = analyzer.plot_log_fit(
                            x_data, y_data,
                            title=f"{x_col} vs {y_col} Log Fit",
                            xlabel=xlabel_in,
                            ylabel=ylabel_in,
                            x_err=x_err,
                            y_err=y_err,
                            slope=slope,
                            intercept=intercept,
                            r_squared=r_squared,
                            slope_err=slope_err,
                            intercept_err=intercept_err,
                            save_path=full_path
                        )

                        st.image(f"data:image/png;base64,{plot_data}", caption="å¯¹æ•°æ‹Ÿåˆå›¾")

                        st.session_state.analysis_result = {
                            "type": "log_fit",
                            "a": slope,
                            "b": intercept,
                            "r_squared": r_squared,
                            "a_err": slope_err,
                            "b_err": intercept_err,
                            "plot_data": plot_data
                        }
                        st.success("âœ… åˆ†æå®Œæˆï¼")
                        # ä¿å­˜ç»Ÿä¸€çš„åˆ†æä¸Šä¸‹æ–‡ï¼Œä¾› LLM åä½œé¡µä½¿ç”¨
                        st.session_state["analysis_payload"] = {
                            "type": "log",
                            "x_col": x_col,
                            "y_col": y_col,
                            "a": slope,
                            "b": intercept,
                            "a_err": slope_err,
                            "b_err": intercept_err,
                            "r_squared": r_squared,
                            "reduced_chi2": chi2r,
                            "figure_hint": "å¯¹æ•°æ‹Ÿåˆå›¾"
                        }
                        st.session_state["plot_file_path"] = full_path
                        st.session_state["plot_file_name"] = fname
                        
                        # ç¬¬ä¸€æ­¥ï¼šçªå‡ºæ˜¾ç¤ºä¸‹ä¸€æ­¥æç¤º
                        st.divider()
                        st.success("ğŸ‰ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼å¯¹æ•°æ‹Ÿåˆå·²ç”Ÿæˆï¼")
                        with st.container(border=True):
                            st.markdown("### ğŸ’¡ ä¸‹ä¸€æ­¥")
                            st.markdown("""
                            åœ¨å·¦ä¾§èœå•é€‰æ‹© **'LLMåä½œ'** ä¸å¤§è¯­è¨€æ¨¡å‹å…±åŒæ’°å†™å®éªŒæ€»ç»“
                            
                            - ğŸ“ Plané˜¶æ®µï¼šæ¾„æ¸…å®éªŒèƒŒæ™¯å’Œæ–¹æ³•
                            - âœï¸ Acté˜¶æ®µï¼šç”Ÿæˆç»“æœåˆ†æå’Œè®¨è®º
                            """)
                        
                        # ç¬¬äºŒæ­¥ï¼šå¤åˆ¶æŒ‰é’®ï¼ˆä½œä¸ºè¾…åŠ©åŠŸèƒ½ï¼‰
                        st.divider()
                        st.subheader("ğŸ“‹ å¤åˆ¶æ‹Ÿåˆç»“æœï¼ˆå¯é€‰ï¼‰")
                        col1, col2 = st.columns(2)
                        with col1:
                            result_txt = f"""å¯¹æ•°æ‹Ÿåˆç»“æœï¼š
ç³»æ•°a: {slope_str} Â± {slope_unc}
æˆªè·b: {intercept_str} Â± {intercept_unc}
åŠ æƒRÂ²: {r_squared:.4f}
Reduced Ï‡Â²: {chi2r:.3f}
å›¾æ–‡ä»¶: {fname}"""
                            st.download_button(
                                "ğŸ“‹ å¤åˆ¶æ‹Ÿåˆç»“æœ",
                                data=result_txt,
                                file_name="log_fit_result.txt",
                                mime="text/plain",
                                use_container_width=True
                            )
                        with col2:
                            st.caption("ğŸ’¡ ç‚¹å‡»ä¸‹è½½æ‹Ÿåˆç»“æœ\nï¼ˆå¯åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ï¼‰")
                except ValueError as e:
                    st.error(f"âŒ å¯¹æ•°æ‹Ÿåˆå¤±è´¥: {e}")

            elif analysis_type == "å‚…é‡Œå¶å˜æ¢":
                with st.spinner("æ­£åœ¨æ‰§è¡Œå‚…é‡Œå¶å˜æ¢..."):
                    freq, magnitude = analyzer.fourier_transform(y_data, sampling_rate=sampling_rate)

                    st.subheader("ğŸ“Š å‚…é‡Œå¶å˜æ¢ç»“æœ")
                    st.write(f"é¢‘ç‡èŒƒå›´: {freq[0]:.4f} - {freq[-1]:.4f}")
                    st.write(f"é¢‘è°±å³°å€¼: {max(magnitude):.4f}")

                    # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°ï¼Œå‘½åï¼šå‚…é‡Œå¶å˜æ¢+æ—¶é—´æˆ³
                    plots_dir = os.path.join(os.getcwd(), "plots")
                    os.makedirs(plots_dir, exist_ok=True)
                    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
                    fname = f"å‚…é‡Œå¶å˜æ¢_{ts}.png"
                    full_path = os.path.join(plots_dir, fname)

                    plot_data = analyzer.plot_fourier_transform(
                        y_data,
                        sampling_rate=sampling_rate,
                        title=f"{y_col} å‚…é‡Œå¶å˜æ¢",
                        save_path=full_path
                    )

                    st.image(f"data:image/png;base64,{plot_data}", caption="é¢‘è°±å›¾")

                    st.session_state.analysis_result = {
                        "type": "fourier_transform",
                        "plot_data": plot_data
                    }
                    
                    # ç¬¬ä¸€æ­¥ï¼šçªå‡ºæ˜¾ç¤ºä¸‹ä¸€æ­¥æç¤º
                    st.divider()
                    st.success("ğŸ‰ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼å‚…é‡Œå¶å˜æ¢å·²ç”Ÿæˆï¼")
                    with st.container(border=True):
                        st.markdown("### ğŸ’¡ ä¸‹ä¸€æ­¥")
                        st.markdown("""
                        åœ¨å·¦ä¾§èœå•é€‰æ‹© **'LLMåä½œ'** ä¸å¤§è¯­è¨€æ¨¡å‹å…±åŒæ’°å†™å®éªŒæ€»ç»“
                        
                        - ğŸ“ Plané˜¶æ®µï¼šæ¾„æ¸…å®éªŒèƒŒæ™¯å’Œæ–¹æ³•
                        - âœï¸ Acté˜¶æ®µï¼šç”Ÿæˆç»“æœåˆ†æå’Œè®¨è®º
                        """)
                    
                    # ç¬¬äºŒæ­¥ï¼šå¤åˆ¶æŒ‰é’®ï¼ˆä½œä¸ºè¾…åŠ©åŠŸèƒ½ï¼‰
                    st.divider()
                    st.subheader("ğŸ“‹ å¤åˆ¶åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰")
                    col1, col2 = st.columns(2)
                    with col1:
                        result_txt = f"""å‚…é‡Œå¶å˜æ¢åˆ†æï¼š
å›¾æ–‡ä»¶: {fname}
åˆ†æåˆ—: {y_col}
é‡‡æ ·ç‡: {sampling_rate} Hz"""
                        st.download_button(
                            "ğŸ“‹ å¤åˆ¶åˆ†æç»“æœ",
                            data=result_txt,
                            file_name="fft_result.txt",
                            mime="text/plain",
                            use_container_width=True
                        )
                    with col2:
                        st.caption("ğŸ’¡ ç‚¹å‡»ä¸‹è½½åˆ†æç»“æœ\nï¼ˆå¯åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ï¼‰")
                    
                    # ä¿å­˜ç»Ÿä¸€çš„åˆ†æä¸Šä¸‹æ–‡ï¼Œä¾› LLM åä½œé¡µä½¿ç”¨
                    st.session_state["analysis_payload"] = {
                        "type": "fft",
                        "y_col": y_col,
                        "sampling_rate": sampling_rate,
                        "peak_magnitude": float(max(magnitude)) if len(magnitude) else None,
                        "figure_hint": "é¢‘è°±å›¾"
                    }
                    st.session_state["plot_file_path"] = full_path
                    st.session_state["plot_file_name"] = fname
                    try:
                        with st.spinner("æ­£åœ¨æ‰§è¡ŒåŒå¯¹æ•°æ‹Ÿåˆ..."):
                            k, C, r_squared, k_err, C_err, chi2r = analyzer.power_fit(
                                x_data, y_data, y_err=y_err
                            )

                            st.subheader("ğŸ“ˆ åŒå¯¹æ•°ï¼ˆå¹‚å¾‹ï¼‰æ‹Ÿåˆç»“æœ")
                            c1, c2, c3 = st.columns(3)
                            k_str, k_unc = analyzer.format_with_uncertainty(k, k_err)
                            C_str, C_unc = analyzer.format_with_uncertainty(C, C_err)
                            c1.metric("å¹‚æŒ‡æ•° k", f"{k_str} Â± {k_unc}")
                            c2.metric("ç³»æ•° C", f"{C_str} Â± {C_unc}")
                            c3.metric("åŠ æƒ RÂ²", f"{r_squared:.4f}")
                            st.caption(f"Reduced $\\chi^2$ = {chi2r:.3f}")

                            # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°ï¼Œå‘½åï¼šåŒå¯¹æ•°æ‹Ÿåˆ+æ—¶é—´æˆ³
                            plots_dir = os.path.join(os.getcwd(), "plots")
                            os.makedirs(plots_dir, exist_ok=True)
                            ts = datetime.now().strftime("%Y%m%d-%H%M%S")
                            fname = f"åŒå¯¹æ•°æ‹Ÿåˆ_{ts}.png"
                            full_path = os.path.join(plots_dir, fname)

                            plot_data = analyzer.plot_power_fit(
                                x_data, y_data,
                                title=f"{x_col} vs {y_col} Power-Law Fit",
                                xlabel=xlabel_in,
                                ylabel=ylabel_in,
                                x_err=x_err,
                                y_err=y_err,
                                k=k,
                                C=C,
                                r_squared=r_squared,
                                k_err=k_err,
                                C_err=C_err,
                                save_path=full_path
                            )

                            st.image(f"data:image/png;base64,{plot_data}", caption="åŒå¯¹æ•°æ‹Ÿåˆå›¾")

                            st.session_state.analysis_result = {
                                "type": "power_fit",
                                "k": k,
                                "C": C,
                                "r_squared": r_squared,
                                "k_err": k_err,
                                "C_err": C_err,
                                "plot_data": plot_data
                            }
                            st.success("âœ… åˆ†æå®Œæˆï¼")
                            st.session_state["plot_file_path"] = full_path
                            st.session_state["plot_file_name"] = fname
                            
                            # ç¬¬ä¸€æ­¥ï¼šçªå‡ºæ˜¾ç¤ºä¸‹ä¸€æ­¥æç¤º
                            st.divider()
                            st.success("ğŸ‰ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼åŒå¯¹æ•°æ‹Ÿåˆå·²ç”Ÿæˆï¼")
                            with st.container(border=True):
                                st.markdown("### ğŸ’¡ ä¸‹ä¸€æ­¥")
                                st.markdown("""
                                åœ¨å·¦ä¾§èœå•é€‰æ‹© **'LLMåä½œ'** ä¸å¤§è¯­è¨€æ¨¡å‹å…±åŒæ’°å†™å®éªŒæ€»ç»“
                                
                                - ğŸ“ Plané˜¶æ®µï¼šæ¾„æ¸…å®éªŒèƒŒæ™¯å’Œæ–¹æ³•
                                - âœï¸ Acté˜¶æ®µï¼šç”Ÿæˆç»“æœåˆ†æå’Œè®¨è®º
                                """)
                            
                            # ç¬¬äºŒæ­¥ï¼šå¤åˆ¶æŒ‰é’®ï¼ˆä½œä¸ºè¾…åŠ©åŠŸèƒ½ï¼‰
                            st.divider()
                            st.subheader("ğŸ“‹ å¤åˆ¶æ‹Ÿåˆç»“æœï¼ˆå¯é€‰ï¼‰")
                            col1, col2 = st.columns(2)
                            with col1:
                                result_txt = f"""åŒå¯¹æ•°æ‹Ÿåˆç»“æœï¼š
å¹‚æŒ‡æ•°: {k_str} Â± {k_unc}
ç³»æ•°C: {C_str} Â± {C_unc}
åŠ æƒRÂ²: {r_squared:.4f}
Reduced Ï‡Â²: {chi2r:.3f}
å›¾æ–‡ä»¶: {fname}"""
                                st.download_button(
                                    "ğŸ“‹ å¤åˆ¶æ‹Ÿåˆç»“æœ",
                                    data=result_txt,
                                    file_name="power_fit_result.txt",
                                    mime="text/plain",
                                    use_container_width=True
                                )
                            with col2:
                                st.caption("ğŸ’¡ ç‚¹å‡»ä¸‹è½½æ‹Ÿåˆç»“æœ\nï¼ˆå¯åœ¨å…¶ä»–åœ°æ–¹ä½¿ç”¨ï¼‰")
                            
                            # ä¿å­˜ç»Ÿä¸€çš„åˆ†æä¸Šä¸‹æ–‡ï¼Œä¾› LLM åä½œé¡µä½¿ç”¨
                            st.session_state["analysis_payload"] = {
                                "type": "power",
                                "x_col": x_col,
                                "y_col": y_col,
                                "k": k,
                                "C": C,
                                "k_err": k_err,
                                "C_err": C_err,
                                "r_squared": r_squared,
                                "reduced_chi2": chi2r,
                                "figure_hint": "åŒå¯¹æ•°æ‹Ÿåˆå›¾"
                            }
                    except ValueError as e:
                        st.error(f"âŒ åŒå¯¹æ•°æ‹Ÿåˆå¤±è´¥: {e}")
    else:
        st.warning("å½“å‰æ•°æ®ä¸åŒ…å«è¶³å¤Ÿçš„æ•°å€¼åˆ—è¿›è¡Œåˆ†æ")
        st.info("è¯·ç¡®ä¿è¡¨æ ¼åŒ…å«è‡³å°‘2åˆ—æ•°å€¼æ•°æ®")

## å·²ç§»é™¤ LaTeX è¾“å‡ºé¡µé¢ï¼Œç»Ÿä¸€åœ¨â€œLLMåä½œâ€é¡µå®Œæˆåä½œå¼ç”Ÿæˆ

def llm_page():
    st.header("LLMåä½œ")
    st.caption("èº«ä»½ï¼šç‰©ç†å®éªŒæŠ¥å‘Šåä½œåŠ©æ‰‹ï½œè§„åˆ™ï¼šç®€æ´å‡ç»ƒã€ç¦æ­¢ç¼–é€ ã€å…ˆæ¾„æ¸…ååŠ¨ç¬”")

    df = st.session_state.get("dataframe")
    analysis_payload = st.session_state.get("analysis_payload")
    plot_file_path = st.session_state.get("plot_file_path")
    plot_file_name = st.session_state.get("plot_file_name")

    with st.expander("ğŸ“„ å¯ç”¨è¡¨æ ¼æ•°æ®ï¼ˆé¢„è§ˆï¼‰", expanded=False):
        if df is not None and not df.empty:
            st.dataframe(df)
        else:
            st.info("æš‚æ— è¡¨æ ¼æ•°æ®ï¼Œè¯·å…ˆå®Œæˆ OCR å¹¶ä¿å­˜è¡¨æ ¼ã€‚")

    with st.expander("ğŸ“Š å¯ç”¨åˆ†æç»“æœï¼ˆJSONï¼‰", expanded=False):
        if analysis_payload:
            st.json(analysis_payload)
        else:
            st.info("æš‚æ— åˆ†æç»“æœï¼Œè¯·å…ˆåœ¨â€˜æ•°æ®åˆ†æâ€™ä¸­å®Œæˆæ‹Ÿåˆã€‚")

    mode = st.radio("åä½œæ¨¡å¼", ["plan", "act"], horizontal=True, help="planï¼šæ¾„æ¸…éœ€æ±‚ä¸åˆ¶å®šè®¡åˆ’ï¼›actï¼šæŒ‰éœ€è¾“å‡ºæ–‡æ®µï¼ˆåªåŒ…å«æ–‡å­—åˆ†æï¼Œä¸ç”¨LLMç”Ÿæˆè¡¨æ ¼/å›¾ç‰‡ï¼‰")
    user_notes = st.text_area("è¡¥å……è¯´æ˜ / é¢å¤–è¦æ±‚ï¼ˆå¯é€‰ï¼‰", height=100)

    llm = LLMProcessor(model=st.session_state.selected_model)

    if mode == "plan":
        if st.button("ç”Ÿæˆè®¡åˆ’ä¸é—®é¢˜æ¸…å•"):
            with st.spinner("AI æ­£åœ¨åˆ¶å®šè®¡åˆ’å¹¶ç¡®è®¤é—®é¢˜..."):
                resp = llm.generate_collab_response(df, analysis_payload, mode="plan", user_notes=user_notes)
                st.subheader("ğŸ§­ åä½œè®¡åˆ’ & éœ€ç¡®è®¤é—®é¢˜")
                st.write(resp)
    else:
        if st.button("æ‰§è¡Œ act è¾“å‡ºï¼ˆæ–‡å­—åˆ†æï¼‰"):
            with st.spinner("AI æ­£åœ¨ç”Ÿæˆæ–‡å­—åˆ†æ..."):
                resp = llm.generate_collab_response(df, analysis_payload, mode="act", act_type="text", user_notes=user_notes)
                st.subheader("ğŸ“ ç»“æœä¸è®¨è®ºï¼ˆæ–‡å­—åˆ†æï¼‰")
                st.write(resp)

    st.divider()
    st.subheader("ğŸ“‹ æ ‡å‡† LaTeX è¡¨æ ¼ç‰‡æ®µï¼ˆæ— éœ€LLMï¼‰")
    if df is not None and not df.empty:
        from latex_generator import LatexGenerator
        generator = LatexGenerator()
        table_caption = "å®éªŒæ•°æ®è¡¨"
        table_label = "tab:data"
        latex_table = generator.generate_table_latex(df, table_caption, table_label)
        st.code(latex_table, language="latex")
    else:
        st.info("æš‚æ— è¡¨æ ¼æ•°æ®")

    st.subheader("ï¿½ï¸ æ ‡å‡† LaTeX æ’å›¾å¼•ç”¨ç‰‡æ®µï¼ˆæ— éœ€LLMï¼‰")
    if plot_file_name and analysis_payload:
        figure_caption = analysis_payload.get("figure_hint", "å®éªŒå›¾")
        figure_latex = f"""
\begin{{figure}}[h]
\centering
\includegraphics[width=0.8\linewidth]{{{plot_file_name}}}
\caption{{{figure_caption}}}
\label{{fig:plot}}
\end{{figure}}
"""
        st.code(figure_latex.strip(), language="latex")
        # æä¾›å›¾ç‰‡ä¸‹è½½ï¼ˆæ–‡ä»¶åä¸ LaTeX ä¸­ä¸€è‡´ï¼‰
        try:
            with open(plot_file_path, "rb") as f:
                st.download_button("ğŸ“¥ ä¸‹è½½å›¾åƒ", data=f.read(), file_name=plot_file_name, mime="image/png")
        except Exception:
            st.warning("å›¾åƒæ–‡ä»¶ä¸å¯ç”¨ï¼Œè¯·é‡æ–°åœ¨æ•°æ®åˆ†æé¡µç”Ÿæˆå›¾åƒã€‚")
    else:
        st.info("æš‚æ— ç”Ÿæˆçš„å›¾åƒï¼Œå…ˆåœ¨æ•°æ®åˆ†æé¡µæ‰§è¡Œæ‹Ÿåˆã€‚")

def llm_page_new():
    st.header("ğŸ’¬ LLM åä½œ")
    st.caption("æ²Ÿé€š(Plan) â†’ æ’°å†™(Act) â†’ æŸ¥çœ‹ç»“æœ")
    
    # æ¨¡å‹é€‰æ‹©
    col1, col2 = st.columns([3, 1])
    with col1:
        st.subheader("ğŸ¤– è¯­è¨€æ¨¡å‹é€‰æ‹©")
    with col2:
        model_options = {
            "qwen-flash-2025-07-28": "âš¡ Flash (å¿«é€Ÿ)",
            "qwen3-max-2025-09-23": "ğŸ’ª Max (é«˜æ€§èƒ½)",
            "qwen-plus-2025-12-01": "ğŸ§  Plus (æ·±åº¦æ€è€ƒ)"
        }
        selected_label = st.radio(
            "é€‰æ‹©æ¨¡å‹",
            options=list(model_options.values()),
            index=list(model_options.keys()).index(st.session_state.selected_model) if st.session_state.selected_model in model_options else 0,
            label_visibility="collapsed"
        )
        # åå‘æŸ¥æ‰¾é€‰ä¸­çš„æ¨¡å‹å
        st.session_state.selected_model = [k for k, v in model_options.items() if v == selected_label][0]
    
    st.divider()

    df = st.session_state.get("dataframe")
    analysis_payload = st.session_state.get("analysis_payload")
    plot_file_path = st.session_state.get("plot_file_path")
    plot_file_name = st.session_state.get("plot_file_name")
    
    # çŠ¶æ€
    in_act_mode = st.session_state.get("in_act_mode", False)
    act_completed = st.session_state.get("act_completed", False)
    
    # å·¦ä¾§æ•°æ®æ¦‚è§ˆ
    with st.sidebar:
        st.divider()
        st.subheader("ğŸ“Š æ•°æ®")
        if df is not None:
            st.caption(f"è¡¨: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            with st.expander("æŸ¥çœ‹", expanded=False):
                st.dataframe(df, height=120, use_container_width=True)
        
        st.divider()
        st.subheader("ğŸ¯ è¯¯å·®åˆ†æ")
        if st.session_state.get("uncertainty_analysis_result"):
            unc_result = st.session_state.uncertainty_analysis_result
            st.success("âœ… å·²å®Œæˆè®¡ç®—")
            st.metric(
                "ç»“æœ",
                f"{unc_result.get('result', 0):.4g} Â± {unc_result.get('uncertainty_total', 0):.3g}"
            )
            st.metric(
                "ç›¸å¯¹ä¸ç¡®å®šåº¦",
                f"{unc_result.get('relative_uncertainty', 0):.2%}"
            )
            with st.expander("è¯¦ç»†ä¿¡æ¯", expanded=False):
                st.markdown(f"**å…¬å¼**: {unc_result.get('raw_formula', 'N/A')}")
                st.markdown(f"**è§„èŒƒå¼**: {unc_result.get('normalized_formula', 'N/A')}")
                if unc_result.get('contributions'):
                    st.markdown("**è´¡çŒ®å æ¯”**:")
                    for var, contrib in unc_result['contributions'].items():
                        st.markdown(f"  - {var}: {contrib:.1f}%")
                if unc_result.get('summary'):
                    st.markdown("---")
                    st.markdown("**AIæ€»ç»“**:")
                    st.markdown(unc_result['summary'])
        else:
            st.info("æš‚æ— è®¡ç®—ç»“æœ")
        
        st.divider()
        st.subheader("ğŸ“ˆ æ‹Ÿåˆç»“æœ")
        if analysis_payload:
            fit_type = analysis_payload.get('type', 'æœªçŸ¥')
            type_names = {
                'linear': 'ğŸ”µ çº¿æ€§æ‹Ÿåˆ',
                'log': 'ğŸŸ  å¯¹æ•°æ‹Ÿåˆ',
                'fft': 'ğŸŸ¡ å‚…é‡Œå¶å˜æ¢',
                'power': 'ğŸ”´ åŒå¯¹æ•°æ‹Ÿåˆ'
            }
            st.success(f"âœ… {type_names.get(fit_type, fit_type)}")
            
            with st.expander("å‚æ•°è¯¦æƒ…", expanded=True):
                analyzer = DataAnalyzer()
                
                if fit_type == 'linear':
                    slope = analysis_payload.get('slope', 0)
                    intercept = analysis_payload.get('intercept', 0)
                    slope_err = analysis_payload.get('slope_err', 0)
                    intercept_err = analysis_payload.get('intercept_err', 0)
                    r_squared = analysis_payload.get('r_squared', 0)
                    
                    slope_str, slope_unc = analyzer.format_with_uncertainty(slope, slope_err)
                    intercept_str, intercept_unc = analyzer.format_with_uncertainty(intercept, intercept_err)
                    
                    st.metric("æ–œç‡", f"{slope_str} Â± {slope_unc}")
                    st.metric("æˆªè·", f"{intercept_str} Â± {intercept_unc}")
                    st.metric("åŠ æƒ RÂ²", f"{r_squared:.4f}")
                    
                elif fit_type == 'log':
                    a = analysis_payload.get('a', 0)
                    b = analysis_payload.get('b', 0)
                    a_err = analysis_payload.get('a_err', 0)
                    b_err = analysis_payload.get('b_err', 0)
                    r_squared = analysis_payload.get('r_squared', 0)
                    
                    a_str, a_unc = analyzer.format_with_uncertainty(a, a_err)
                    b_str, b_unc = analyzer.format_with_uncertainty(b, b_err)
                    
                    st.metric("ç³»æ•° a", f"{a_str} Â± {a_unc}")
                    st.metric("æˆªè· b", f"{b_str} Â± {b_unc}")
                    st.metric("åŠ æƒ RÂ²", f"{r_squared:.4f}")
                    
                elif fit_type == 'fft':
                    sampling_rate = analysis_payload.get('sampling_rate', 'N/A')
                    peak_magnitude = analysis_payload.get('peak_magnitude', 'N/A')
                    st.metric("é‡‡æ ·ç‡", f"{sampling_rate} Hz")
                    if isinstance(peak_magnitude, (int, float)):
                        st.metric("å³°å€¼å¹…åº¦", f"{peak_magnitude:.6g}")
                    else:
                        st.metric("å³°å€¼å¹…åº¦", f"{peak_magnitude}")
                        
                elif fit_type == 'power':
                    k = analysis_payload.get('k', 0)
                    C = analysis_payload.get('C', 0)
                    k_err = analysis_payload.get('k_err', 0)
                    C_err = analysis_payload.get('C_err', 0)
                    r_squared = analysis_payload.get('r_squared', 0)
                    
                    k_str, k_unc = analyzer.format_with_uncertainty(k, k_err)
                    C_str, C_unc = analyzer.format_with_uncertainty(C, C_err)
                    
                    st.metric("å¹‚æŒ‡æ•° k", f"{k_str} Â± {k_unc}")
                    st.metric("ç³»æ•° C", f"{C_str} Â± {C_unc}")
                    st.metric("åŠ æƒ RÂ²", f"{r_squared:.4f}")
                    st.metric("RÂ²", f"{analysis_payload.get('r_squared', 'N/A'):.4f}")
            
            if plot_file_name:
                st.info(f"ğŸ–¼ï¸ å›¾: {plot_file_name}")
        else:
            st.warning("âš ï¸ è¯·å…ˆå®Œæˆæ•°æ®åˆ†æ")
        
        st.divider()
        if st.button("ğŸ”„ é‡ç½®", use_container_width=True):
            for k in ["chat_history", "context_initialized", "in_act_mode", "act_completed", "act_response"]:
                st.session_state.pop(k, None)
            st.rerun()
    
    # LLM åˆå§‹åŒ–
    try:
        llm = LLMProcessor(model=st.session_state.selected_model)
    except ValueError as e:
        st.error(f"âŒ {str(e)}")
        return
    
    # ===== PLAN é˜¶æ®µ =====
    if not in_act_mode and not act_completed:
        # åˆå§‹åŒ–
        if not st.session_state.get("context_initialized", False):
            init = "ä½ å¥½ï¼æˆ‘æ˜¯ç‰©ç†å®éªŒæŠ¥å‘ŠåŠ©æ‰‹ã€‚å·²è¯»å–ä½ çš„æ•°æ®å’Œåˆ†æã€‚è¯·å‘Šè¯‰æˆ‘ï¼š\n1. å®éªŒåç§°å’Œç›®æ ‡\n2. æµ‹é‡æ–¹æ³•\n3. å…³é”®å‚æ•°\n4. éªŒè¯çš„ç‰©ç†è§„å¾‹"
            st.session_state.chat_history = [{"role": "assistant", "content": init}]
            st.session_state.context_initialized = True
        
        # æ˜¾ç¤ºå¯¹è¯
        for msg in st.session_state.get("chat_history", []):
            with st.chat_message(msg["role"], avatar="ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"):
                st.markdown(msg["content"])
        
        # è¾“å…¥
        if inp := st.chat_input("æè¿°å®éªŒ..."):
            st.chat_message("user", avatar="ğŸ‘¤").markdown(inp)
            st.session_state.chat_history.append({"role": "user", "content": inp})
            
            ctx = {"dataframe": df, "analysis_payload": analysis_payload} if len(st.session_state.chat_history) <= 3 else None
            
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                ph = st.empty()
                resp = ""
                thinking_text = ""
                # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨plusæ¨¡å‹å¹¶å¯ç”¨æ·±åº¦æ€è€ƒ
                enable_thinking = "plus" in st.session_state.selected_model
                try:
                    for chunk_obj in llm.chat_stream(inp, st.session_state.chat_history[:-1], ctx, enable_thinking=enable_thinking):
                        if isinstance(chunk_obj, dict):
                            chunk_type = chunk_obj.get("type", "")
                            chunk_text = chunk_obj.get("text", "")
                            
                            if chunk_type == "thinking":
                                thinking_text += chunk_text
                            elif chunk_type == "content":
                                resp += chunk_text
                        else:
                            # å‘åå…¼å®¹ï¼šå¦‚æœè¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—å…¸
                            resp += str(chunk_obj)
                        
                        # å®æ—¶æ˜¾ç¤ºå†…å®¹å’Œæ€è€ƒè¿‡ç¨‹
                        if thinking_text and resp:
                            display_text = f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```\n\n---\n\n{resp}â–Œ"
                        elif thinking_text:
                            display_text = f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```â–Œ"
                        else:
                            display_text = resp + "â–Œ"
                        ph.markdown(display_text)
                    
                    # æœ€ç»ˆæ˜¾ç¤ºï¼ˆå»é™¤å…‰æ ‡ï¼‰
                    if thinking_text and resp:
                        display_text = f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```\n\n---\n\n{resp}"
                    elif thinking_text:
                        display_text = f"ğŸ§  **æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```"
                    else:
                        display_text = resp
                    ph.markdown(display_text)
                    
                    st.session_state.chat_history.append({"role": "assistant", "content": resp})
                except Exception as e:
                    ph.error(f"âŒ {e}")
        
        # Act æŒ‰é’®
        st.divider()
        col1, col2 = st.columns([2, 3])
        with col1:
            if st.button("âœ… å¼€å§‹æ’°å†™", use_container_width=True, type="primary"):
                st.session_state.in_act_mode = True
                st.rerun()
        with col2:
            st.caption("ğŸ’¡ æ²Ÿé€šå®Œæˆåï¼Œç‚¹å‡»è¿›å…¥æ’°å†™é˜¶æ®µ")
    
    # ===== ACT é˜¶æ®µ =====
    elif in_act_mode and not act_completed:
        st.subheader("ğŸ“ æ’°å†™æŠ¥å‘Šç‰‡æ®µ")
        st.caption("æ ¹æ®æ²Ÿé€šå†…å®¹ç”Ÿæˆç²¾ç®€çš„å®éªŒæŠ¥å‘Šç‰‡æ®µï¼ˆéå®Œæ•´æŠ¥å‘Šï¼‰")
        
        mod = st.text_area("ä¿®æ”¹è¦æ±‚ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹ï¼šåŠ ä¸Šä¸ç¡®å®šåº¦è®¨è®º", height=60)
        
        col1, col2 = st.columns([2, 1])
        with col1:
            if st.button("ğŸš€ ç”Ÿæˆ", use_container_width=True):
                try:
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        ph = st.empty()
                        resp = ""
                        thinking_text = ""
                        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨plusæ¨¡å‹å¹¶å¯ç”¨æ·±åº¦æ€è€ƒ
                        enable_thinking = "plus" in st.session_state.selected_model
                        uncertainty_result = st.session_state.get("passed_uncertainty_result")
                        uncertainty_conversation = st.session_state.get("passed_uncertainty_conversation")
                        
                        for chunk_obj in llm.generate_act_response(df, analysis_payload, st.session_state.get("chat_history", []), mod, enable_thinking=enable_thinking, uncertainty_result=uncertainty_result, uncertainty_conversation=uncertainty_conversation):
                            if isinstance(chunk_obj, dict):
                                chunk_type = chunk_obj.get("type", "")
                                chunk_text = chunk_obj.get("text", "")
                                
                                if chunk_type == "thinking":
                                    thinking_text += chunk_text
                                elif chunk_type == "content":
                                    resp += chunk_text
                            else:
                                # å‘åå…¼å®¹ï¼šå¦‚æœè¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—å…¸
                                resp += str(chunk_obj)
                        
                        # æœ€ç»ˆæ˜¾ç¤ºï¼ˆå»é™¤å…‰æ ‡ï¼‰
                        if thinking_text and resp:
                            display_text = f"ğŸ§  **æ·±åº¦æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```\n\n---\n\n{resp}"
                        elif thinking_text:
                            display_text = f"ğŸ§  **æ·±åº¦æ€è€ƒè¿‡ç¨‹**\n\n```\n{thinking_text}\n```"
                        else:
                            display_text = resp
                        ph.markdown(display_text)
                        
                        st.session_state.act_response = resp
                        st.session_state.act_completed = True
                        st.success("ğŸ‰ æŠ¥å‘Šç‰‡æ®µå·²ç”Ÿæˆï¼")
                        st.rerun()
                except Exception as e:
                    st.error(f"âŒ {e}")
        with col2:
            if st.button("â†©ï¸ å›åˆ°æ²Ÿé€š", use_container_width=True):
                st.session_state.in_act_mode = False
                st.rerun()
    
    # ===== ç»“æœå±•ç¤º =====
    elif act_completed:
        st.subheader("âœ¨ ç»“æœ")
        
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ æŠ¥å‘Š", "ğŸ“‹ è¡¨", "ğŸ–¼ï¸ å›¾", "ğŸ“¥ ä¸‹è½½"])
        
        with tab1:
            st.caption("ç”Ÿæˆçš„æŠ¥å‘Šç‰‡æ®µ")
            st.code(st.session_state.get("act_response", ""), language="latex")
            if st.button("âœï¸ é‡æ–°ç”Ÿæˆ"):
                st.session_state.in_act_mode = True
                st.session_state.act_completed = False
                st.rerun()
        
        with tab2:
            if df is not None:
                from latex_generator import LatexGenerator
                gen = LatexGenerator()
                tbl = gen.generate_table_latex(df, "å®éªŒæ•°æ®è¡¨", "tab:data")
                st.code(tbl, language="latex")
            else:
                st.info("æš‚æ— æ•°æ®")
        
        with tab3:
            if plot_file_name and analysis_payload:
                fig_cap = analysis_payload.get("figure_hint", "æ‹Ÿåˆ")
                fig_tex = f"""\\\\begin{{figure}}[h]
\\\\centering
\\\\includegraphics[width=0.8\\\\linewidth]{{{plot_file_name}}}
\\\\caption{{{fig_cap}}}
\\\\label{{fig:plot}}
\\\\end{{figure}}"""
                st.code(fig_tex, language="latex")
            else:
                st.info("æš‚æ— å›¾è¡¨")
        
        with tab4:
            if plot_file_path and plot_file_name:
                try:
                    with open(plot_file_path, "rb") as f:
                        st.download_button(f"ğŸ“¥ {plot_file_name}", data=f.read(), file_name=plot_file_name, mime="image/png", use_container_width=True)
                except:
                    st.warning("å›¾åƒä¸å¯ç”¨")
        
        st.divider()
        st.subheader("ğŸ“¦ å®Œæ•´æŠ¥å‘ŠåŒ…ä¸‹è½½")
        st.caption("åŒ…å«ï¼šç”Ÿæˆçš„æŠ¥å‘Šç‰‡æ®µï¼ˆLaTeXï¼‰ + æ•°æ®è¡¨ï¼ˆLaTeXï¼‰ + å›¾åƒï¼ˆPNGï¼‰+ æ•°æ®ï¼ˆCSVï¼‰")
        
        if st.button("â¬‡ï¸ ç”Ÿæˆå¹¶ä¸‹è½½å®Œæ•´åŒ…", use_container_width=True):
            try:
                import zipfile
                import io
                
                # åˆ›å»º ZIP æ–‡ä»¶ï¼ˆåœ¨å†…å­˜ä¸­ï¼‰
                zip_buffer = io.BytesIO()
                
                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                    # 1. æ·»åŠ ç”Ÿæˆçš„æŠ¥å‘Šç‰‡æ®µ
                    act_resp = st.session_state.get("act_response", "")
                    if act_resp:
                        zf.writestr("report_segment.tex", act_resp)
                    
                    # 2. æ·»åŠ æ•°æ®è¡¨çš„ LaTeX
                    if df is not None:
                        from latex_generator import LatexGenerator
                        gen = LatexGenerator()
                        table_latex = gen.generate_table_latex(df, "å®éªŒæ•°æ®è¡¨", "tab:data")
                        zf.writestr("data_table.tex", table_latex)
                        
                        # 3. æ·»åŠ æ•°æ®ï¼ˆCSVï¼‰
                        csv_data = df.to_csv(index=False)
                        zf.writestr("data_table.csv", csv_data)
                    
                    # 4. æ·»åŠ å›¾åƒ
                    if plot_file_path:
                        try:
                            with open(plot_file_path, "rb") as f:
                                zf.writestr(plot_file_name or "plot.png", f.read())
                        except:
                            pass
                    
                    # 5. æ·»åŠ è‡ªå®šä¹‰ LaTeXï¼ˆå¦‚æœ‰ï¼‰
                    custom_latex = st.session_state.get("custom_latex", "")
                    if custom_latex:
                        zf.writestr("custom_content.tex", custom_latex)
                    
                    # 6. æ·»åŠ  README
                    readme = """# ç‰©ç†å®éªŒæŠ¥å‘Šæ–‡ä»¶åŒ…

æ­¤åŒ…åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

1. **report_segment.tex** - AI ç”Ÿæˆçš„æŠ¥å‘Šç‰‡æ®µ
2. **data_table.tex** - å®éªŒæ•°æ®è¡¨ï¼ˆLaTeX æ ¼å¼ï¼‰
3. **data_table.csv** - å®éªŒæ•°æ®è¡¨ï¼ˆCSV æ ¼å¼ï¼‰
4. **plot.png** - æ‹Ÿåˆæ›²çº¿æˆ–åˆ†æå›¾åƒ
5. **custom_content.tex** - è‡ªå®šä¹‰ LaTeX å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰
6. **README.md** - æœ¬æ–‡ä»¶

## ä½¿ç”¨è¯´æ˜

1. å°†è¿™äº›æ–‡ä»¶å¤åˆ¶åˆ°æ‚¨çš„ LaTeX é¡¹ç›®ç›®å½•
2. åœ¨ä¸»æ–‡æ¡£ä¸­ä½¿ç”¨ \\input{report_segment.tex} å¯¼å…¥æŠ¥å‘Šç‰‡æ®µ
3. æ ¹æ®éœ€è¦è°ƒæ•´å›¾åƒå¤§å°å’Œä½ç½®
4. ç¼–è¯‘ç”Ÿæˆ PDF

## æ³¨æ„

- ç¡®ä¿ \\includegraphics å‘½ä»¤ä¸­çš„æ–‡ä»¶åä¸å®é™…æ–‡ä»¶åŒ¹é…
- å¯èƒ½éœ€è¦è°ƒæ•´è¡¨æ ¼å’Œå›¾åƒçš„æ ¼å¼ä»¥ç¬¦åˆæ‚¨çš„æ–‡æ¡£é£æ ¼
- è‡ªå®šä¹‰ LaTeX å†…å®¹å¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¼–è¾‘
"""
                    zf.writestr("README.md", readme)
                
                # å‡†å¤‡ä¸‹è½½
                zip_buffer.seek(0)
                st.download_button(
                    "ğŸ“¦ ä¸‹è½½å®Œæ•´æŠ¥å‘ŠåŒ…ï¼ˆZIPï¼‰",
                    data=zip_buffer.getvalue(),
                    file_name="physics_report_package.zip",
                    mime="application/zip",
                    type="primary",
                    use_container_width=True
                )
                st.success("ğŸ‰ **ç¬¬ä¸‰é˜¶æ®µå®Œæˆï¼** å®Œæ•´æŠ¥å‘ŠåŒ…å·²å‡†å¤‡å¥½ï¼åŒ…å«ï¼šæŠ¥å‘Šç‰‡æ®µ + æ•°æ®è¡¨ + å›¾åƒ + CSVæ•°æ®")
                st.balloons()
                st.success("âœ… å®Œæ•´åŒ…å·²å‡†å¤‡å¥½ï¼åŒ…å«æŠ¥å‘Šã€è¡¨æ ¼ã€å›¾åƒå’Œæ•°æ®ã€‚")
            except Exception as e:
                st.error(f"âŒ æ‰“åŒ…å¤±è´¥: {e}")
        
        st.divider()
        if st.button("ğŸ”„ æ–°å®éªŒ", use_container_width=True):
            for k in ["chat_history", "context_initialized", "in_act_mode", "act_completed", "act_response"]:
                st.session_state.pop(k, None)
            st.rerun()

if __name__ == "__main__":
    main()
